{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "import json\n",
    "import pandas as pd\n",
    "file_name_1 = \"Segment prediction/raw data/train_data.json\"\n",
    "with open(file_name_1, 'r') as jsonfile1:\n",
    "    data_dict_1 = json.load(jsonfile1)\n",
    "train = pd.DataFrame.from_dict(data_dict_1, orient='index')\n",
    "del data_dict_1\n",
    "train.reset_index(level=0, inplace=True)\n",
    "train.rename(columns = {'index':'ID'},inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'tod', 'genres', 'titles', 'cities', 'segment', 'dow']\n"
     ]
    }
   ],
   "source": [
    "print(list(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID segment                                        cities  \\\n0      train-1     neg                     gurgaon:55494,delhi:31892   \n1     train-10     neg             delhi:5862,nagar:8916,mumbai:1593   \n2    train-100     neg                              navi mumbai:4142   \n3   train-1000     neg  new delhi:4131,chennai:2878,navi mumbai:1339   \n4  train-10000     neg                     gurgaon:6077,chennai:4055   \n\n                                                 tod  \\\n0  10:26,13:331,12:323,20:21864,21:16233,17:7953,...   \n1  11:1661,10:384,20:401,21:798,22:221,16:525,19:...   \n2                                1:1207,0:2406,2:529   \n3        11:71,20:2417,21:1042,23:2288,19:1872,8:658   \n4  20:158,22:4139,17:67,23:1510,19:288,18:56,0:23...   \n\n                                   genres  \\\n0  Cricket:82379,Kabaddi:255,Reality:4751   \n1              Cricket:15640,Wildlife:730   \n2                 LiveTV:13,Football:4129   \n3               TalkShow:658,Cricket:7690   \n4    Drama:5503,Cricket:3283,Reality:1345   \n\n                                                 dow  \\\n0  1:3412,3:15878,2:1737,5:10975,4:20974,7:17820,...   \n1      1:5745,3:3025,2:3346,5:123,4:3007,7:1108,6:10   \n2                                             3:4142   \n3                     1:658,3:5867,5:413,4:1339,7:71   \n4                  1:1641,2:480,4:1445,7:1663,6:4900   \n\n                                              titles  \n0  Top Raids: Haryana vs Services SCB:103,Day 4: ...  \n1  Dhoni Quits Captaincy:148,Day 4: India Move in...  \n2  Star Sports 4:13,Manchester United vs Everton:...  \n3  SRH vs RCB:701,KKR vs KXIP:1042,MI vs SRH:2288...  \n4  MI vs KKR:304,Yeh Rishta Kya Kehlata Hai:5449,...  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_converter(x):\n",
    "    if x== \"\":\n",
    "        return {}\n",
    "    \n",
    "    lst = []\n",
    "    for m in x.split(\",\"):\n",
    "        if m =='':\n",
    "            continue\n",
    "        f,y = m.rsplit(\":\",1)\n",
    "        lst.append((f,int(y)))\n",
    "    \n",
    "    return dict(lst)\n",
    "\n",
    "def dow_labeller(x):\n",
    "    k = []\n",
    "    for i in x.split(\",\"):\n",
    "        i = \"dow\"+i \n",
    "        k.append(i)\n",
    "    k = \",\".join(k)\n",
    "    return k\n",
    "\n",
    "def tod_labeller(x):\n",
    "    k = []\n",
    "    for i in x.split(\",\"):\n",
    "        i = \"tod\"+i \n",
    "        k.append(i)\n",
    "    k = \",\".join(k)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time to do the vectoriseing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "vec = DictVectorizer()\n",
    "\n",
    "train['dow_encoded'] = train['dow'].apply(dow_labeller)\n",
    "train['tod_encoded'] = train['tod'].apply(tod_labeller)\n",
    "\n",
    "#Todo need to combine all the colums and add a special unique label for dow and tod\n",
    "features_str= train[['genres','dow_encoded', 'tod_encoded', 'titles','cities']].\\\n",
    "    apply(lambda x: ','.join(x), axis=1)\n",
    "\n",
    "#target_train = train[\"segment\"]\n",
    "\n",
    "#Encode Target Variable\n",
    "target_train = le.fit_transform(train[\"segment\"])\n",
    "#now we delete the original data from memory\n",
    "del train\n",
    "#convert to dicts\n",
    "dict_features  = features_str.apply(dict_converter)\n",
    "\n",
    "sparce_matrix = vec.fit_transform(dict_features)\n",
    "#remove the dict features because a sparce matrix now exists\n",
    "del dict_features\n",
    "#print(sparce_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaling all the information\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sparce_matrix = StandardScaler(with_mean=False).fit_transform(sparce_matrix)\n",
    "#sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using the pipeling\n",
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "#label_encoder = preprocessing.LabelEncoder()\n",
    "#encoded_target_y_train= label_encoder.fit_transform(y_train)\n",
    "\n",
    "parameters = {'min_samples_split':[120,400,800]}\n",
    "#clf = RandomForestClassifier(oob_score=True,n_estimators=30,max_features =2)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "grid = GridSearchCV(clf, parameters,scoring='roc_auc')\n",
    "\n",
    "t0 = time()\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0)) \n",
    "#print(sorted(clf.cv_results_.keys()))\n",
    "#print(clf.cv_results_)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "def report(results, n_top=10):\n",
    "    print(\"Report generated at {}\".format(strftime(\"%d-%m-%Y %H:%M:%S\")))\n",
    "    print(\"\")\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.6f} (std: {1:.6f}),average time:{2:.3f}\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate],\n",
    "                results[\"mean_fit_time\"][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 11932.62 seconds for 100 candidates parameter settings.\nReport generated at 28-06-2017 17:18:11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nModel with rank: 1\nMean validation score: 0.827025 (std: 0.004220),average time:35.593\nParameters: {'learning_rate': 0.074328918328445445, 'reg_lambda': 0.42678029949742707, 'subsample': 0.96846932037563438, 'max_depth': 7, 'colsample_bytree': 0.35670493653765878, 'n_estimators': 170}\n\nModel with rank: 2\nMean validation score: 0.826928 (std: 0.005382),average time:43.444\nParameters: {'learning_rate': 0.145907868143172, 'reg_lambda': 1.6759095377781985, 'subsample': 0.81878581631716152, 'max_depth': 5, 'colsample_bytree': 0.72438232769269661, 'n_estimators': 182}\n\nModel with rank: 3\nMean validation score: 0.826834 (std: 0.004380),average time:34.186\nParameters: {'learning_rate': 0.1105041056296911, 'reg_lambda': 1.0693131482316618, 'subsample': 0.76491427861680505, 'max_depth': 6, 'colsample_bytree': 0.56182934177578192, 'n_estimators': 155}\n\nModel with rank: 4\nMean validation score: 0.826822 (std: 0.004998),average time:43.402\nParameters: {'learning_rate': 0.11399894858281655, 'reg_lambda': 1.1593338635468282, 'subsample': 0.90934904302873165, 'max_depth': 7, 'colsample_bytree': 0.58117042771537353, 'n_estimators': 174}\n\nModel with rank: 5\nMean validation score: 0.826626 (std: 0.004727),average time:26.971\nParameters: {'learning_rate': 0.15240601270441628, 'reg_lambda': 1.0598288265803959, 'subsample': 0.70952829555566532, 'max_depth': 4, 'colsample_bytree': 0.39158407741120027, 'n_estimators': 215}\n\nModel with rank: 6\nMean validation score: 0.826603 (std: 0.005313),average time:37.431\nParameters: {'learning_rate': 0.12988883281473629, 'reg_lambda': 1.2780975149141021, 'subsample': 0.69920999451526344, 'max_depth': 5, 'colsample_bytree': 0.59083653194292685, 'n_estimators': 182}\n\nModel with rank: 7\nMean validation score: 0.826491 (std: 0.004887),average time:22.325\nParameters: {'learning_rate': 0.078417933095923764, 'reg_lambda': 1.2341532744541233, 'subsample': 0.78375521162492268, 'max_depth': 5, 'colsample_bytree': 0.33015538589800669, 'n_estimators': 183}\n\nModel with rank: 8\nMean validation score: 0.826283 (std: 0.004377),average time:36.316\nParameters: {'learning_rate': 0.15279330653946707, 'reg_lambda': 1.7440545768422828, 'subsample': 0.85552332152768074, 'max_depth': 7, 'colsample_bytree': 0.34144743295209823, 'n_estimators': 203}\n\nModel with rank: 9\nMean validation score: 0.826206 (std: 0.005231),average time:39.232\nParameters: {'learning_rate': 0.075128576270065917, 'reg_lambda': 1.0380367445187269, 'subsample': 0.92824766002250603, 'max_depth': 5, 'colsample_bytree': 0.57114339034066408, 'n_estimators': 206}\n\nModel with rank: 10\nMean validation score: 0.826198 (std: 0.004318),average time:33.406\nParameters: {'learning_rate': 0.11249697985002011, 'reg_lambda': 0.97901484884070977, 'subsample': 0.55439258414546266, 'max_depth': 5, 'colsample_bytree': 0.63407341213678203, 'n_estimators': 179}\n\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "from time import strftime\n",
    "import numpy as np\n",
    "\n",
    "# build a classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "\n",
    "param_dist = {\"learning_rate\":sp_uniform(0.01,0.4),\n",
    "              #\"gamma\":sp_uniform(0.001,30),\n",
    "              \"n_estimators\":sp_randint(150,220),\n",
    "              \"max_depth\":sp_randint(3,8),\n",
    "              \"colsample_bytree\":sp_uniform(0.3,0.5),\n",
    "               'subsample': np.random.uniform(0.5,1,1000),\n",
    "               'reg_lambda': sp_uniform(0.3,1.5)\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,scoring='roc_auc',cv=None\n",
    "                                   )\n",
    "\n",
    "start = time()\n",
    "random_search.fit(sparce_matrix, target_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "\n",
    "# activate this when fitting models\n",
    "current_time = strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "joblib.dump(random_search, 'Segment prediction/classifier pickle dump/'\n",
    "                           'segment prediction_{0} pv score {1:.6f}.pkl'.format(current_time,\n",
    "                                                                        random_search.best_score_))\n",
    "\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated at 22-06-2017 00:03:51\n\nModel with rank: 1\nMean validation score: 0.827363 (std: 0.004511),average time:46.605\nParameters: {'reg_lambda': 1.1554720354390606, 'n_estimators': 202, 'colsample_bytree': 0.71198994591581355, 'subsample': 0.7232702377618665, 'max_depth': 6, 'learning_rate': 0.11801404268080393}\n\nModel with rank: 2\nMean validation score: 0.823433 (std: 0.004854),average time:23.699\nParameters: {'reg_lambda': 0.8214060039127089, 'n_estimators': 125, 'colsample_bytree': 0.70377985227615791, 'subsample': 0.99173723170900918, 'max_depth': 4, 'learning_rate': 0.098782826890588052}\n\nModel with rank: 3\nMean validation score: 0.822420 (std: 0.003790),average time:15.952\nParameters: {'reg_lambda': 0.57704789716848337, 'n_estimators': 93, 'colsample_bytree': 0.46030457478925302, 'subsample': 0.75079320699186769, 'max_depth': 5, 'learning_rate': 0.28759071515500184}\n\nModel with rank: 4\nMean validation score: 0.820113 (std: 0.004900),average time:15.343\nParameters: {'reg_lambda': 1.2949906443075645, 'n_estimators': 136, 'colsample_bytree': 0.35073483532874072, 'subsample': 0.71391490740101848, 'max_depth': 4, 'learning_rate': 0.050592572441467261}\n\nModel with rank: 5\nMean validation score: 0.819595 (std: 0.005016),average time:17.934\nParameters: {'reg_lambda': 1.252181133053915, 'n_estimators': 61, 'colsample_bytree': 0.73749610062050097, 'subsample': 0.98116128901229427, 'max_depth': 5, 'learning_rate': 0.084802257682404111}\n\nModel with rank: 6\nMean validation score: 0.819219 (std: 0.003345),average time:31.350\nParameters: {'reg_lambda': 0.55360076485712129, 'n_estimators': 213, 'colsample_bytree': 0.60437959455924561, 'subsample': 0.64392899624803501, 'max_depth': 4, 'learning_rate': 0.29342978740674658}\n\nModel with rank: 7\nMean validation score: 0.816933 (std: 0.004128),average time:19.733\nParameters: {'reg_lambda': 0.49440405836490592, 'n_estimators': 108, 'colsample_bytree': 0.39477768251895839, 'subsample': 0.84979426044974726, 'max_depth': 7, 'learning_rate': 0.33036927326372689}\n\nModel with rank: 8\nMean validation score: 0.816675 (std: 0.005696),average time:31.839\nParameters: {'reg_lambda': 0.38946219575841484, 'n_estimators': 97, 'colsample_bytree': 0.78762408236150905, 'subsample': 0.61135925680288672, 'max_depth': 7, 'learning_rate': 0.018894089377332515}\n\nModel with rank: 9\nMean validation score: 0.816361 (std: 0.004090),average time:15.051\nParameters: {'reg_lambda': 1.0651214099324287, 'n_estimators': 143, 'colsample_bytree': 0.31739013551556139, 'subsample': 0.60216057225913644, 'max_depth': 5, 'learning_rate': 0.35401909824865635}\n\nModel with rank: 10\nMean validation score: 0.813344 (std: 0.006237),average time:28.284\nParameters: {'reg_lambda': 1.2077787349651796, 'n_estimators': 199, 'colsample_bytree': 0.37112472806639635, 'subsample': 0.70212435177658838, 'max_depth': 5, 'learning_rate': 0.01096342204635449}\n\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params {'learning_rate': 0.145907868143172, 'reg_lambda': 1.6759095377781985, 'subsample': 0.81878581631716152, 'max_depth': 5, 'colsample_bytree': 0.72438232769269661, 'n_estimators': 182}\nbest score 100.826928412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1,\n       colsample_bytree=0.72438232769269661, gamma=0,\n       learning_rate=0.145907868143172, max_delta_step=0, max_depth=5,\n       min_child_weight=1, missing=None, n_estimators=182, nthread=-1,\n       objective='binary:logistic', reg_alpha=0,\n       reg_lambda=1.6759095377781985, scale_pos_weight=1, seed=0,\n       silent=True, subsample=0.81878581631716152)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params =random_search.cv_results_[\"params\"]\n",
    "scores = random_search.cv_results_[\"mean_test_score\"]\n",
    "params_df = pd.DataFrame(data=list(zip(scores,params)),\n",
    "                         columns=[\"scores\",\"params\"])\n",
    "params_df.sort_values(by=\"scores\",inplace=True)\n",
    "loc = -2\n",
    "a = params_df.iloc[loc][\"params\"]\n",
    "print(\"params\",a)\n",
    "best_score =  100+params_df.iloc[loc][\"scores\"]\n",
    "print(\"best score\",best_score)\n",
    "special_clf = XGBClassifier(**a)\n",
    "special_clf.fit(sparce_matrix, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now time to submit the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "#submitting stuff\n",
    "file_name_2 = \"Segment prediction/raw data/test_data.json\"\n",
    "with open(file_name_2, 'r') as jsonfile2:\n",
    "    data_dict_2 = json.load(jsonfile2)\n",
    "\n",
    "test = pd.DataFrame.from_dict(data_dict_2, orient='index')\n",
    "del data_dict_2\n",
    "test.reset_index(level=0, inplace=True)\n",
    "test.rename(columns = {'index':'ID'},inplace=True)\n",
    "submission_df = pd.DataFrame(data = test[\"ID\"])\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'dow', 'genres', 'cities', 'titles', 'tod']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to sparce matrix test\n",
    "\n",
    "test['dow_encoded'] = test['dow'].apply(dow_labeller)\n",
    "test['tod_encoded'] = test['tod'].apply(tod_labeller)\n",
    "\n",
    "#Todo need to combine all the colums and add a special unique label for dow and tod\n",
    "features_str_test= test[['genres','dow_encoded', 'tod_encoded', 'titles','cities']].\\\n",
    "    apply(lambda x: ','.join(x), axis=1)\n",
    "\n",
    "del test\n",
    "dict_features_test  = features_str_test.apply(dict_converter)\n",
    "del features_str_test\n",
    "\n",
    "sparce_matrix_test = vec.transform(dict_features_test)\n",
    "del dict_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#can skip to this if the test data is loaded and model is trained\n",
    "import numpy as np\n",
    "from time import strftime\n",
    "\n",
    "# View probabilities\n",
    "probs_test = random_search.predict_proba(sparce_matrix_test)\n",
    "#probs_test = special_clf.predict_proba(sparce_matrix_test)\n",
    "\n",
    "#del sparce_matrix_test\n",
    "submission_df[\"segment\"] = probs_test[:,1]\n",
    "\n",
    "\n",
    "current_time = strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "submission_df.to_csv(\"Segment prediction/output_data/segment_prediction_output_{0}\"\n",
    "                     \" pv score {1:.6f}.csv\".format(current_time,random_search.best_score_)\n",
    "                     ,index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}